{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **D3TOP – Tópicos em Ciência de Dados** \n",
        "# **Processamento de Linguagem Natural**\n",
        "\n",
        "\n",
        "#**Professor:**\n",
        "# Samuel Martins \n",
        "\n",
        "\n",
        "##**Alunos:**\n",
        "# Caio Francisco Garcia de Lima \n",
        "\n",
        "#Carlos Caetano de Almeida "
      ],
      "metadata": {
        "id": "ueMqES1WlN8n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Descrição e motivação do problema**\n",
        "\n",
        "LinkS doS VídeoS do Projeto: \n",
        "\n",
        "https://drive.google.com/file/d/15cT9cVAR_XGQOPe_eBAKZey8AgU-5KgV/view\n",
        "\n",
        "https://drive.google.com/file/d/15XYHtS8bDT69N1x1eofQyeeGzRl83vJV/view\n",
        "\n",
        "https://watch.screencastify.com/v/LDq982zbvADj5cwoMwtb\n",
        "\n",
        "A tecnologia de inteligência artificial (IA) do ChatGPT tem se despontado na mídia como um dos maiores avanços computacionais já vistos, ampliando-se a discussão dos usos da IA, bem como do perigo para a Humanidade.\n",
        "\n",
        "Tais avanços serviu como motivação para desenvolver um projeto que pudesse utilizar da base de dados do ChatGPT para realizar o processamento de linguagem natural (PLN) em voz, texto e imagem.\n",
        "\n",
        "O projeto vai permitir que uma pergunta seja feita através do microfone, a partir de então há o processamento desse áudio, de forma que a IA a interprete e pesquise a sua resposta que será dada na forma textural, baseada nessa reposta, a IA irá gerar uma imagem sobre a resposta para a pergunta.\n",
        "\n",
        "O ChatGPT possui Engines específicas para o PLN que serão descritas mais abaixo\n",
        "\n",
        "Nos negócios, a comunicação eficaz com os clientes é essencial para o sucesso. À medida que a interação com os clientes evolui, as empresas buscam soluções que possam fornecer respostas rápidas e precisas às consultas dos clientes, melhorar a experiência do usuário e aumentar a eficiência operacional.\n",
        "\n",
        "Uma abordagem promissora é o uso de chatbots baseados em inteligência artificial, que podem responder a perguntas, fornecer suporte ao cliente e até mesmo realizar transações simples. No entanto, a maioria dos chatbots tradicionais possui limitações em sua capacidade de entender e responder de forma inteligente a uma ampla variedade de perguntas e situações.\n",
        "\n",
        "Motivação para o ChatGPT nos Negócios:\n",
        "O ChatGPT (baseado na tecnologia GPT, da OpenAI) apresenta-se como uma solução avançada para chatbots nos negócios. Ele utiliza um modelo de linguagem poderoso e pré-treinado em uma grande quantidade de dados para gerar respostas contextualmente relevantes e humanas.\n",
        "\n",
        "A principal vantagem do ChatGPT nos negócios é sua capacidade de lidar com uma ampla gama de consultas e situações complexas. Ele pode entender perguntas em linguagem natural, interpretar comandos, fornecer informações detalhadas sobre produtos e serviços, auxiliar em processos de tomada de decisão e até mesmo lidar com reclamações e problemas dos clientes.\n",
        "\n",
        "Além disso, o ChatGPT é altamente escalável, o que significa que pode lidar com um grande volume de consultas simultaneamente, permitindo que as empresas atendam a um grande número de clientes de forma eficiente e rápida.\n",
        "\n",
        "Outra vantagem é a capacidade de personalização do ChatGPT. As empresas podem treinar o modelo com dados específicos de seu setor, produtos ou serviços, aprimorando ainda mais sua capacidade de fornecer respostas relevantes e personalizadas.\n",
        "\n",
        "Ao utilizar o ChatGPT nos negócios, as empresas podem melhorar a satisfação do cliente, reduzir o tempo de resposta, aumentar a eficiência operacional e liberar recursos humanos para tarefas mais complexas. Isso resulta em um melhor atendimento ao cliente, maior retenção, aumento das vendas e vantagem competitiva no mercado.\n",
        "\n",
        "\n",
        "\n",
        "## **Objetivo de negócio ou científico associado ao problema**\n",
        "\n",
        "###**Objetivo de Negócio:**\n",
        "\n",
        "O objetivo de negócio associado ao problema seria melhorar a experiência do cliente, aumentar a satisfação e fidelidade do cliente, e impulsionar o crescimento dos negócios. Isso pode ser alcançado por meio da implementação eficaz do ChatGPT para fornecer um suporte ao cliente de alta qualidade, respostas rápidas e precisas às consultas dos clientes e soluções personalizadas para suas necessidades. O objetivo é fortalecer o relacionamento com o cliente, promover interações positivas e aumentar a eficiência operacional.\n",
        "\n",
        "###**Objetivo Científico:**\n",
        "\n",
        "O objetivo científico associado ao problema seria aprimorar a capacidade do modelo de ChatGPT em compreender e responder de forma mais precisa e contextualmente relevante às consultas dos clientes. Isso envolve treinar o modelo em dados específicos do setor ou do negócio para melhorar sua compreensão e conhecimento sobre tópicos relevantes. Além disso, seria importante explorar técnicas de adaptação de domínio para garantir que o ChatGPT possa lidar com perguntas específicas de negócios e se adaptar a novos cenários ou atualizações de produtos e serviços. O objetivo é melhorar continuamente a qualidade e a inteligência das respostas geradas pelo ChatGPT para atender às necessidades e expectativas dos clientes."
      ],
      "metadata": {
        "id": "Ri3TTvlSlWn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **INSTALANDO BIBLIOTECA OPENAI - CHATGPT**"
      ],
      "metadata": {
        "id": "iHlXO4pVlelh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV_hqKqTYkFf",
        "outputId": "fb119ca0-cf80-44c7-9961-a0efc1997de2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: py: command not found\n"
          ]
        }
      ],
      "source": [
        "!py -m pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!py -m pip install pyttsx3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z604RyUAawLo",
        "outputId": "509cc3f4-97f8-47d5-e645-387a159d6b45"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: py: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!py -m pip install SpeechRecognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sFWUlwna7GQ",
        "outputId": "d61f8698-3c2a-4b74-d88f-a27a10a87eac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: py: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install espeak"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6j0g8nFe3ha",
        "outputId": "d6d31e08-a6a2-4799-eded-227ce3466022"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  espeak-data libespeak1 libportaudio2 libsonic0\n",
            "The following NEW packages will be installed:\n",
            "  espeak espeak-data libespeak1 libportaudio2 libsonic0\n",
            "0 upgraded, 5 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 1,220 kB of archives.\n",
            "After this operation, 3,060 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 libportaudio2 amd64 19.6.0-1build1 [65.4 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 libsonic0 amd64 0.2.0-8 [13.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 espeak-data amd64 1.48.04+dfsg-8build1 [932 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal/universe amd64 libespeak1 amd64 1.48.04+dfsg-8build1 [147 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal/universe amd64 espeak amd64 1.48.04+dfsg-8build1 [61.8 kB]\n",
            "Fetched 1,220 kB in 1s (824 kB/s)\n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 122542 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1build1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1build1) ...\n",
            "Selecting previously unselected package libsonic0:amd64.\n",
            "Preparing to unpack .../libsonic0_0.2.0-8_amd64.deb ...\n",
            "Unpacking libsonic0:amd64 (0.2.0-8) ...\n",
            "Selecting previously unselected package espeak-data:amd64.\n",
            "Preparing to unpack .../espeak-data_1.48.04+dfsg-8build1_amd64.deb ...\n",
            "Unpacking espeak-data:amd64 (1.48.04+dfsg-8build1) ...\n",
            "Selecting previously unselected package libespeak1:amd64.\n",
            "Preparing to unpack .../libespeak1_1.48.04+dfsg-8build1_amd64.deb ...\n",
            "Unpacking libespeak1:amd64 (1.48.04+dfsg-8build1) ...\n",
            "Selecting previously unselected package espeak.\n",
            "Preparing to unpack .../espeak_1.48.04+dfsg-8build1_amd64.deb ...\n",
            "Unpacking espeak (1.48.04+dfsg-8build1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1build1) ...\n",
            "Setting up libsonic0:amd64 (0.2.0-8) ...\n",
            "Setting up espeak-data:amd64 (1.48.04+dfsg-8build1) ...\n",
            "Setting up libespeak1:amd64 (1.48.04+dfsg-8build1) ...\n",
            "Setting up espeak (1.48.04+dfsg-8build1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!py -m pip install pyttsx3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u0JnmoVdUAH",
        "outputId": "2a160681-4eab-4c61-d516-de16e37da6be"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: py: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install portaudio19-dev\n",
        "!py -m pip install pipwin\n",
        "!py -m pipwin install pyaudio\n",
        "!py -m pip install path/to/pyaudio.whl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYdk9o8KgFQX",
        "outputId": "ea1ad4fb-e50e-4775-8e35-2cc00b609624"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libportaudiocpp0\n",
            "Suggested packages:\n",
            "  portaudio19-doc\n",
            "The following NEW packages will be installed:\n",
            "  libportaudiocpp0 portaudio19-dev\n",
            "0 upgraded, 2 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 122 kB of archives.\n",
            "After this operation, 702 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 libportaudiocpp0 amd64 19.6.0-1build1 [16.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 portaudio19-dev amd64 19.6.0-1build1 [106 kB]\n",
            "Fetched 122 kB in 1s (138 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libportaudiocpp0:amd64.\n",
            "(Reading database ... 122867 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudiocpp0_19.6.0-1build1_amd64.deb ...\n",
            "Unpacking libportaudiocpp0:amd64 (19.6.0-1build1) ...\n",
            "Selecting previously unselected package portaudio19-dev:amd64.\n",
            "Preparing to unpack .../portaudio19-dev_19.6.0-1build1_amd64.deb ...\n",
            "Unpacking portaudio19-dev:amd64 (19.6.0-1build1) ...\n",
            "Setting up libportaudiocpp0:amd64 (19.6.0-1build1) ...\n",
            "Setting up portaudio19-dev:amd64 (19.6.0-1build1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "/bin/bash: py: command not found\n",
            "/bin/bash: py: command not found\n",
            "/bin/bash: py: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!py -m pip install pyaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSqYbHF6daDm",
        "outputId": "a3ed4053-636b-4d49-8394-9330e09deedd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: py: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DEFININDO CHAVE PESSOAL CHATGPT**\n",
        "\n",
        "1 - Acesse a página de gerenciamento da API da OpenAI em https://beta.openai.com/account/api-keys.\n",
        "\n",
        "2 - Selecione a chave que você deseja usar ou crie uma nova clicando no botão \"Generate New Key\".\n",
        "\n",
        "3 - Copie a chave API exibida na tela.\n",
        "\n",
        "4 - No seu código Python, defina a chave API como uma variável de ambiente chamada OPENAI_API_KEY."
      ],
      "metadata": {
        "id": "6jG_w7LuZkyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = \"INSIRA A SUA CHAVE AQUI\""
      ],
      "metadata": {
        "id": "yGtaTav2lnhH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ENGINES** \n",
        "\n",
        "A biblioteca OpenAI fornece várias engines que podem ser usadas para realizar tarefas diferentes. Aqui estão algumas das engines mais conhecidas e suas funcionalidades:\n",
        "\n",
        "**Davinci:** é a engine mais poderosa e completa, projetada para realizar tarefas complexas de processamento de linguagem natural, incluindo geração de texto, tradução de idiomas, responder perguntas, completar frases e muito mais.\n",
        "\n",
        "**Curie:** é uma engine de processamento de linguagem natural com menor capacidade que a Davinci, mas ainda assim poderosa o suficiente para realizar tarefas como geração de texto, tradução de idiomas e respostas a perguntas.\n",
        "\n",
        "**Babbage:** é uma engine de processamento de linguagem natural básica que pode realizar tarefas como geração de texto e respostas a perguntas simples.\n",
        "\n",
        "**Ada:** é uma engine de processamento de linguagem natural projetada para interagir com usuários finais e fornecer respostas relevantes a perguntas comuns.\n",
        "\n",
        "**Codex:** é uma engine de linguagem natural voltada para programação, que pode gerar código a partir de descrições em linguagem natural, corrigir erros de sintaxe e completar trechos de código.\n",
        "\n",
        "**GPT-3:** é uma engine de processamento de linguagem natural com 175 bilhões de parâmetros, projetada para realizar tarefas como geração de texto, tradução de idiomas, respostas a perguntas, completar frases e muito mais.\n",
        "\n",
        "**GPT-2:** é uma engine de processamento de linguagem natural semelhante ao GPT-3, mas com menos parâmetros (1,5 bilhão).\n",
        "\n",
        "**DALL-E:** é uma engine de geração de imagem que pode gerar imagens a partir de descrições de texto.\n",
        "\n",
        "**CLIP:** é uma engine de visão computacional que foi treinada para entender a relação entre imagens e texto.\n",
        "\n",
        "Cada engine é projetada para realizar tarefas específicas e tem suas próprias limitações e funcionalidades. A escolha da engine certa depende da tarefa que você deseja realizar."
      ],
      "metadata": {
        "id": "DjoSzQY7ZpY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyttsx3  #Biblioteca responsavel pela leitura da maquina, converte texto para voz\n",
        "import openai #API do chatgpt\n",
        "import speech_recognition as sr #Biblioteca responsavel pelo reconhecimento de voz, converte voz para texto\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "\n",
        "engine = pyttsx3.init()\n",
        "\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "r = sr.Recognizer()\n",
        "mic = sr.Microphone(device_index=1) #Escolhe o microfone da máquina/notebook\n",
        "\n",
        "conversation = \"\" #Variavel para pegar as perguntas que o usuário faz ao chatbot\n",
        "\n",
        "user_name = \"user\" \n",
        "\n",
        "#--------------Programa da conversa entre o usuário e chatbot--------------#\n",
        "\n",
        "def generate_image(prompt):\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json',\n",
        "        'Authorization': 'Bearer OPENAI_API_KEY' # Chave da API\n",
        "    }\n",
        "\n",
        "    # set up the request data\n",
        "    data = {\n",
        "        'prompt': prompt,\n",
        "        'size': '256x256', # set the size of the generated image\n",
        "        'response_format': 'url' # request the image to be returned as a URL\n",
        "    }\n",
        "\n",
        "    # send the request to the DALL-E 2 API\n",
        "    response = requests.post('https://api.openai.com/v1/images/generations', headers=headers, json=data)\n",
        "\n",
        "    # parse the response to get the image URL\n",
        "    response_json = response.json()\n",
        "    image_url = response_json['data'][0]['url']\n",
        "\n",
        "    # download and return the image\n",
        "    response = requests.get(image_url)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "    return img\n",
        "\n",
        "\n",
        "\n",
        "while True: \n",
        "    with mic as source: #Habilita o Mic para receber a voz, depois de recebido o input, ele espera 0.2 segundos para alocar o conteúdo em um variavel chamada audio\n",
        "        print(\"Ouvindo...\")\n",
        "        r.adjust_for_ambient_noise(source=source, duration=0.2)\n",
        "        audio = r.listen(source)\n",
        "        \n",
        "    print(\"Respondendo..\")\n",
        "\n",
        "    try: \n",
        "        user_input=r.recognize_google(audio) #O programa tenta reconhecer o conteúdo de audio, utilizando um reconhecedor do google para isso\n",
        "        \n",
        "\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "    prompt = user_name+\": \"+user_input+\"\\nChatbot: \"\n",
        "    conversation += prompt\n",
        "\n",
        "    print(f\"\\n{conversation}\")\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": user_input }]\n",
        "    )\n",
        "\n",
        "\n",
        "    #response = openai.Completion.create(\n",
        "    #engine=\"text-davinci-003\",\n",
        "    #prompt=conversation,\n",
        "    #temperature=0.7,\n",
        "    #max_tokens=100\n",
        "    #)\n",
        "\n",
        "\n",
        "    response_str = response['choices'][0]['message']['content']\n",
        "\n",
        "\n",
        "    print(response_str+\"\\n\")\n",
        "\n",
        "    engine.say(response_str)\n",
        "\n",
        "    img = generate_image(response_str)\n",
        "    img.show()\n",
        "    engine.runAndWait()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "d8sY8AaeY-lk",
        "outputId": "1d230af2-0344-40ba-e233-253f84df7924"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-8fa013105624>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyttsx3\u001b[0m  \u001b[0;31m#Biblioteca responsavel pela leitura da maquina, converte texto para voz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopenai\u001b[0m \u001b[0;31m#API do chatgpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspeech_recognition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msr\u001b[0m \u001b[0;31m#Biblioteca responsavel pelo reconhecimento de voz, converte voz para texto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyttsx3'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qpned4IUbatr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}